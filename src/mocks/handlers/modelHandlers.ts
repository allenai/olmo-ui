import type { Model } from '@/api/playgroundApi/additionalTypes';
import type { SchemaResponseModel } from '@/api/playgroundApi/playgroundApiSchema';

import {
    defaultInferenceConstraintsCamel,
    defaultInferenceConstraintsSnake,
} from './defaultInferenceConstraints';
import { typedHttp } from './typedHttp';

export const fakeModelsResponse = [
    {
        description: "AI2's 7B model trained on the Dolma dataset and fine-tuned for chat.",
        id: 'olmo-7b-chat',
        model_type: 'chat',
        host: 'modal',
        name: 'Olmo 7B - Chat',
        information_url: 'https://allenai.org',
        is_deprecated: true,
        family_id: 'olmo',
        family_name: 'Olmo',
        is_visible: false,
        prompt_type: 'text_only',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
    },
    {
        description: 'A 70B parameter model that is a fine-tuned version of Llama 2.',
        id: 'tulu2',
        model_type: 'chat',
        host: 'inferd',
        name: 'Tulu2.5',
        is_deprecated: false,
        family_id: 'tulu',
        family_name: 'Tülu',
        is_visible: true,
        prompt_type: 'text_only',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
    },
    {
        description: "AI2's 7B model following the 'peteish' thread of improvements.",
        host: 'modal',
        id: 'Olmo-peteish-dpo-preview',
        is_deprecated: false,
        model_type: 'chat',
        name: 'Olmo-peteish-dpo-preview',
        information_url: 'https://allenai.org',
        is_visible: true,
        prompt_type: 'text_only',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
    },
    {
        description: 'Molmo',
        id: 'molmo',
        model_type: 'chat',
        host: 'inferd',
        name: 'Molmo',
        is_deprecated: false,
        accepts_files: true,
        accepted_file_types: ['image/*'],
        is_visible: true,
        prompt_type: 'multi_modal',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
        // inference test overrides below
        temperature_default: 0,
        max_tokens_default: 1024,
        max_tokens_upper: 4096,
    },
    {
        description: 'A fake model with thinking',
        id: 'thinking-model',
        model_type: 'chat',
        host: 'test_backend',
        name: 'Thinking fake model',
        is_deprecated: false,
        is_visible: true,
        prompt_type: 'text_only',
        internal: false,
        can_think: true,
    },
    {
        description: 'A fake model with tool calling',
        id: 'tool-calling-model',
        model_type: 'chat',
        host: 'test_backend',
        name: 'Tool calling fake model',
        is_deprecated: false,
        is_visible: true,
        prompt_type: 'text_only',
        internal: false,
        can_think: false,
        can_call_tools: true,
    },
    {
        description: 'A fake model with thinking and tool calling',
        id: 'thinking-and-tool-calling-model',
        model_type: 'chat',
        host: 'test_backend',
        name: 'Thinking and tool calling fake model',
        is_deprecated: false,
        is_visible: true,
        prompt_type: 'text_only',
        internal: false,
        can_think: true,
        can_call_tools: true,
    },
] satisfies Array<Model>;

const fakeAdminModelsResponse: SchemaResponseModel[] = [
    {
        availableTime: null,
        createdTime: '2025-04-29T17:03:50.726370+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'description',
        familyId: null,
        familyName: null,
        host: 'modal',
        id: 'new-test-model',
        internal: true,
        modelIdOnHost: 'foo',
        modelType: 'chat',
        name: 'new-test-model',
        order: 0,
        promptType: 'text_only',
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        availableTime: null,
        createdTime: '2025-04-25T18:16:49.831683+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'A 405B parameter model that is a fine-tuned version of Llama 2.',
        familyId: 'tulu',
        familyName: 'Tülu',
        host: 'inferd',
        id: 'tulu3-405b',
        internal: true,
        modelIdOnHost: 'csc_01jjqp4s2x3hq6e05j3a0h3f96',
        modelType: 'chat',
        name: 'Llama Tülu 3 405B-test2',
        order: 1,
        promptType: 'text_only',
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        availableTime: null,
        createdTime: '2025-04-25T20:25:13.122286+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'foo',
        familyId: 'tulu',
        familyName: 'Tülu',
        host: 'inferd',
        id: 'test-model-5',
        internal: true,
        modelIdOnHost: 'csc_01jjqp4s2x3hq6e05j3a0h3f96',
        modelType: 'chat',
        name: 'Llama Tülu 3 405B-test22',
        order: 2,
        promptType: 'text_only',
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        availableTime: null,
        createdTime: '2025-04-29T17:04:22.850975+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'description',
        familyId: null,
        familyName: null,
        host: 'modal',
        id: 'new-test-model-2',
        internal: true,
        modelIdOnHost: 'foo',
        modelType: 'chat',
        name: 'new-test-model-2',
        order: 3,
        promptType: 'text_only',
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        acceptedFileTypes: ['image/*', 'application/pdf'],
        allowFilesInFollowups: null,
        availableTime: '2025-04-27T02:41:42+00:00',
        createdTime: '2025-04-29T20:00:26.072706+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'This model is made for testing',
        familyId: null,
        familyName: null,
        host: 'inferd',
        id: 'test-multi-modal-model-16',
        internal: false,
        maxFilesPerMessage: null,
        maxTotalFileSize: 5_242_880,
        modelIdOnHost: 'test-multi-modal-model-id',
        modelType: 'chat',
        name: 'model made for testing',
        order: 6,
        promptType: 'multi_modal',
        requireFileToPrompt: null,
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
];

const v4ModelsHandler = typedHttp.get('/v4/models/', ({ response }) => {
    return response(200).json(fakeModelsResponse);
});

const adminModelsHandler = typedHttp.get('/v4/admin/models/', ({ response }) => {
    return response(200).json(fakeAdminModelsResponse);
});

export const modelHandlers = [v4ModelsHandler, adminModelsHandler];
