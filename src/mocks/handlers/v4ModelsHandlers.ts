import type { SchemaModelResponse } from '@/api/playgroundApi/playgroundApiSchema';

import { defaultInferenceConstraintsSnake } from './defaultInferenceConstraints';
import { typedHttp } from './typedHttp';

export const fakeModelsResponse = [
    {
        description: "AI2's 7B model trained on the Dolma dataset and fine-tuned for chat.",
        id: 'olmo-7b-chat',
        model_type: 'chat',
        host: 'modal',
        name: 'Olmo 7B - Chat',
        is_deprecated: true,
        family_id: 'olmo',
        family_name: 'Olmo',
        is_visible: false, // this model is first in the data, but doesn't render in the list because it's not visible
        prompt_type: 'text_only',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
    },
    {
        description: 'A 70B parameter model that is a fine-tuned version of Llama 2.',
        id: 'tulu2',
        model_type: 'chat',
        host: 'inferd',
        name: 'Tulu2.5',
        information_url: 'https://allenai.org',
        is_deprecated: false,
        family_id: 'tulu',
        family_name: 'TÃ¼lu',
        is_visible: true,
        prompt_type: 'text_only',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
    },
    {
        description: "AI2's 7B model following the 'peteish' thread of improvements.",
        host: 'modal',
        id: 'Olmo-peteish-dpo-preview',
        is_deprecated: false,
        model_type: 'chat',
        name: 'Olmo-peteish-dpo-preview',
        information_url: 'https://allenai.org',
        is_visible: true,
        prompt_type: 'text_only',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
    },
    {
        description: 'Molmo',
        id: 'molmo',
        model_type: 'chat',
        host: 'inferd',
        name: 'Molmo',
        is_deprecated: false,
        accepts_files: true,
        accepted_file_types: ['image/*'],
        is_visible: true,
        prompt_type: 'multi_modal',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
        temperature_default: 0,
        max_tokens_default: 1024,
        max_tokens_upper: 4096,
        max_total_file_size: 5_242_880,
    },
    {
        description: 'Molmo 2',
        id: 'molmo2',
        model_type: 'chat',
        host: 'inferd',
        name: 'Molmo 2',
        is_deprecated: false,
        accepts_files: true,
        accepted_file_types: ['image/*', 'video/*'],
        is_visible: true,
        prompt_type: 'multi_modal',
        internal: false,
        infini_gram_index: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsSnake,
        temperature_default: 0,
        max_tokens_default: 1024,
        max_tokens_upper: 4096,
        max_files_per_message: 10,
        max_total_file_size: 5_242_880,
    },
    {
        accepted_file_types: ['image/*', 'video/*'],
        accepts_files: true,
        allow_files_in_followups: false,
        available_tools: [],
        can_call_tools: true,
        can_think: false,
        description: 'A fake multimodal model to test with',
        family_id: null,
        family_name: null,
        host: 'test_backend',
        id: 'test-mm-model',
        infini_gram_index: null,
        information_url: null,
        internal: true,
        is_deprecated: false,
        is_visible: true,
        max_files_per_message: 6,
        max_tokens_default: 2048,
        max_tokens_lower: 1,
        max_tokens_step: 1,
        max_tokens_upper: 2048,
        max_total_file_size: 52428800,
        model_type: 'chat',
        name: 'Test Multimodal Model',
        prompt_type: 'multi_modal',
        require_file_to_prompt: 'first_message',
        stop_default: null,
        system_prompt: null,
        temperature_default: 0.7,
        temperature_lower: 0,
        temperature_step: 0.01,
        temperature_upper: 1,
        top_p_default: 1,
        top_p_lower: 0,
        top_p_step: 0.01,
        top_p_upper: 1,
    },
] satisfies SchemaModelResponse;

const v4ModelsHandler = typedHttp.get('/v4/models/', ({ response }) => {
    return response(200).json(fakeModelsResponse);
});

export const v4ModelsHandlers = [v4ModelsHandler];
