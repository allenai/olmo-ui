import {
    SchemaModelConfigListResponse,
    SchemaModelListResponse,
} from '@/api/playgroundApi/v5playgroundApiSchema';

import { defaultInferenceConstraintsCamel } from './defaultInferenceConstraints';
import { v5TypedHttp } from './v5TypedHttp';

const fakeAdminModelsResponse = [
    {
        availableTime: null,
        createdTime: '2025-04-29T17:03:50.726370+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'description',
        informationUrl: 'https://allenai.org',
        familyId: null,
        familyName: null,
        host: 'modal',
        id: 'new-test-model',
        internal: true,
        modelIdOnHost: 'foo',
        modelType: 'chat',
        name: 'new-test-model',
        order: 0,
        promptType: 'text_only',
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        availableTime: null,
        createdTime: '2025-04-25T18:16:49.831683+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'A 405B parameter model that is a fine-tuned version of Llama 2.',
        familyId: 'tulu',
        familyName: 'Tülu',
        host: 'inferd',
        id: 'tulu3-405b',
        internal: true,
        modelIdOnHost: 'csc_01jjqp4s2x3hq6e05j3a0h3f96',
        modelType: 'chat',
        name: 'Llama Tülu 3 405B-test2',
        order: 1,
        promptType: 'text_only',
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        availableTime: null,
        createdTime: '2025-04-25T20:25:13.122286+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'foo',
        familyId: 'tulu',
        familyName: 'Tülu',
        host: 'inferd',
        id: 'test-model-5',
        internal: true,
        modelIdOnHost: 'csc_01jjqp4s2x3hq6e05j3a0h3f96',
        modelType: 'chat',
        name: 'Llama Tülu 3 405B-test22',
        order: 2,
        promptType: 'text_only',
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        availableTime: null,
        createdTime: '2025-04-29T17:04:22.850975+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'description',
        familyId: null,
        familyName: null,
        host: 'modal',
        id: 'new-test-model-2',
        internal: true,
        modelIdOnHost: 'foo',
        modelType: 'chat',
        name: 'new-test-model-2',
        order: 3,
        promptType: 'text_only',
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        acceptedFileTypes: ['image/*', 'application/pdf'],
        allowFilesInFollowups: null,
        availableTime: '2025-04-27T02:41:42+00:00',
        createdTime: '2025-04-29T20:00:26.072706+00:00',
        defaultSystemPrompt: null,
        deprecationTime: null,
        description: 'This model is made for testing',
        informationUrl: 'https://allenai.org',
        familyId: null,
        familyName: null,
        host: 'inferd',
        id: 'test-multi-modal-model-16',
        internal: false,
        maxFilesPerMessage: null,
        maxTotalFileSize: 5_242_880,
        modelIdOnHost: 'test-multi-modal-model-id',
        modelType: 'chat',
        name: 'model made for testing',
        order: 6,
        promptType: 'multi_modal',
        requireFileToPrompt: null,
        updatedTime: '2025-05-07T22:40:01.919975+00:00',
        availability: 'public',
        canCallTools: false,
        canThink: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
] satisfies SchemaModelConfigListResponse;

const adminModelsHandler = v5TypedHttp.get('/v5/admin/models/', ({ response }) => {
    return response(200).json(fakeAdminModelsResponse);
});

export const fakeModelsResponse = [
    {
        description: "AI2's 7B model trained on the Dolma dataset and fine-tuned for chat.",
        id: 'olmo-7b-chat',
        modelType: 'chat',
        host: 'modal',
        name: 'Olmo 7B - Chat',
        isDeprecated: true,
        familyId: 'olmo',
        familyName: 'Olmo',
        isVisible: false, // this model is first in the data, but doesn't render in the list because it's not visible
        promptType: 'text_only',
        internal: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        description: 'A 70B parameter model that is a fine-tuned version of Llama 2.',
        id: 'tulu2',
        modelType: 'chat',
        host: 'inferd',
        name: 'Tulu2.5',
        informationUrl: 'https://allenai.org',
        isDeprecated: false,
        familyId: 'tulu',
        familyName: 'Tülu',
        isVisible: true,
        promptType: 'text_only',
        internal: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        description: "AI2's 7B model following the 'peteish' thread of improvements.",
        host: 'modal',
        id: 'Olmo-peteish-dpo-preview',
        isDeprecated: false,
        modelType: 'chat',
        name: 'Olmo-peteish-dpo-preview',
        informationUrl: 'https://allenai.org',
        isVisible: true,
        promptType: 'text_only',
        internal: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
    },
    {
        description: 'Molmo',
        id: 'molmo',
        modelType: 'chat',
        host: 'inferd',
        name: 'Molmo',
        isDeprecated: false,
        acceptsFiles: true,
        acceptedFileTypes: ['image/*'],
        isVisible: true,
        promptType: 'multi_modal',
        internal: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
        temperatureDefault: 0,
        maxTokensDefault: 1024,
        maxTokensUpper: 4096,
        maxTotalFileSize: 5_242_880,
    },
    {
        description: 'Molmo 2',
        id: 'molmo2',
        modelType: 'chat',
        host: 'inferd',
        name: 'Molmo 2',
        isDeprecated: false,
        acceptsFiles: true,
        acceptedFileTypes: ['image/*', 'video/*'],
        isVisible: true,
        promptType: 'multi_modal',
        internal: false,
        infiniGramIndex: 'olmoe-0125-1b-7b',
        ...defaultInferenceConstraintsCamel,
        temperatureDefault: 0,
        maxTokensDefault: 1024,
        maxTokensUpper: 4096,
        maxFilesPerMessage: 10,
        maxTotalFileSize: 5_242_880,
    },
    {
        acceptedFileTypes: ['image/*', 'video/*'],
        acceptsFiles: true,
        allowFilesInFollowups: false,
        availableTools: [],
        canCallTools: true,
        canThink: false,
        description: 'A fake multimodal model to test with',
        familyId: null,
        familyName: null,
        host: 'test_backend',
        id: 'test-mm-model',
        infiniGramIndex: null,
        informationUrl: null,
        internal: true,
        isDeprecated: false,
        isVisible: true,
        maxFilesPerMessage: 6,
        maxTokensDefault: 2048,
        maxTokensLower: 1,
        maxTokensStep: 1,
        maxTokensUpper: 2048,
        maxTotalFileSize: 52428800,
        modelType: 'chat',
        name: 'Test Multimodal Model',
        promptType: 'multi_modal',
        requireFileToPrompt: 'first_message',
        stopDefault: null,
        systemPrompt: null,
        temperatureDefault: 0.7,
        temperatureLower: 0,
        temperatureStep: 0.01,
        temperatureUpper: 1,
        topPDefault: 1,
        topPLower: 0,
        topPStep: 0.01,
        topPUpper: 1,
    },
] satisfies SchemaModelListResponse;

const publicModelsHandler = v5TypedHttp.get('/v5/models/', ({ response }) => {
    return response(200).json(fakeModelsResponse);
});

export const v5ModelsHandlers = [adminModelsHandler, publicModelsHandler];
